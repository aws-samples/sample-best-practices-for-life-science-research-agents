Parameters:
  DynamoDbTableName:
    Type: String
    Description: Table name for the DynamoDb instance used to store evidence
    Default: "deep-research-evidence"
  UserProfileName:
    Type: String
    Description: The user profile name for the SageMaker workshop
    Default: "SageMakerUser"
  DomainName:
    Type: String
    Description: The domain name of the Sagemaker studio instance
    Default: "MyDomain"
  CodeRepository:
    Type: String
    Description: The URL of a code repository to suggest in the Studio Git window
    Default: "https://github.com/aws-samples/sample-best-practices-for-life-science-research-agents"
  CodeBuildProjectName:
    Type: String
    Default: "workshop-content-builder"
    Description: "Name of the CodeBuild project"
  CodeBuildGitHubRepository:
    Type: String
    Default: "https://github.com/aws-samples/sample-best-practices-for-life-science-research-agents.git"
    Description: "GitHub repository URL"
  CodeBuildGitHubBranch:
    Type: String
    Default: "main"
    Description: "GitHub branch to build from"

Resources:
  ResearchEvidenceTable:
    Type: AWS::DynamoDB::Table
    DeletionPolicy: Delete
    UpdateReplacePolicy: Delete
    Metadata:
      cfn_nag:
        rules_to_suppress:
          - id: W28
            reason: "Explicit table name required for workshop consistency and agent configuration"
    Properties:
      TableName: !Ref DynamoDbTableName
      AttributeDefinitions:
        - AttributeName: evidence_id
          AttributeType: S
        - AttributeName: source
          AttributeType: S
      KeySchema:
        - AttributeName: evidence_id
          KeyType: HASH
      GlobalSecondaryIndexes:
        - IndexName: source_index
          KeySchema:
            - AttributeName: source
              KeyType: HASH
          Projection:
            ProjectionType: ALL
      BillingMode: PAY_PER_REQUEST
      SSESpecification:
        SSEEnabled: true
        SSEType: KMS
      PointInTimeRecoverySpecification:
        PointInTimeRecoveryEnabled: true

  DynamoDBTableNameParameter:
    Type: AWS::SSM::Parameter
    Properties:
      Name: /deep-research-workshop/table-name
      Description: DynamoDB table name for deep research workshop
      Type: String
      Value: !Ref ResearchEvidenceTable

  DynamoDBTableArnParameter:
    Type: AWS::SSM::Parameter
    Properties:
      Name: /deep-research-workshop/table-arn
      Description: DynamoDB table ARN for deep research workshop
      Type: String
      Value: !GetAtt ResearchEvidenceTable.Arn

  StudioBucket:
    Type: AWS::S3::Bucket
    DeletionPolicy: Delete
    UpdateReplacePolicy: Delete
    Properties:
      BucketEncryption:
        ServerSideEncryptionConfiguration:
          - ServerSideEncryptionByDefault:
              SSEAlgorithm: AES256
      LoggingConfiguration:
        LogFilePrefix: s3-logs
      PublicAccessBlockConfiguration:
        BlockPublicAcls: true
        BlockPublicPolicy: true
        IgnorePublicAcls: true
        RestrictPublicBuckets: true
      BucketName: !Join
        - "-"
        - - "sagemaker-studio"
          - !Select
            - 0
            - !Split
              - "-"
              - !Select
                - 2
                - !Split
                  - "/"
                  - !Ref "AWS::StackId"

  S3BucketNameParameter:
    Type: AWS::SSM::Parameter
    Properties:
      Name: /deep-research-workshop/s3-bucket-name
      Description: Amazon S3 bucket name for deep research workshop
      Type: String
      Value: !Ref StudioBucket

  S3BucketPolicy:
    Type: "AWS::S3::BucketPolicy"
    Properties:
      Bucket: !Ref StudioBucket
      PolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Action:
              - s3:GetObject
              - s3:PutObject
              - s3:GetObjectVersion
            Effect: Allow
            Resource:
              - !Sub ${StudioBucket.Arn}/*
            Principal:
              AWS: !Ref AWS::AccountId
          - Action:
              - s3:GetBucketAcl
              - s3:GetBucketLocation
              - s3:PutBucketPolicy
            Effect: Allow
            Resource:
              - !GetAtt StudioBucket.Arn
            Principal:
              AWS: !Ref AWS::AccountId

  SageMakerExecutionRole:
    Type: AWS::IAM::Role
    Metadata:
      cfn_nag:
        rules_to_suppress:
          - id: W11
            reason: "Wildcard permissions required for SageMaker service discovery and AgentCore operations"
          - id: W76
            reason: "High SPCM acceptable for SageMaker execution role with multiple service integrations"
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Sid: AssumeOtherServiceRoles
            Effect: Allow
            Principal:
              Service:
                - sagemaker.amazonaws.com
            Action:
              - sts:AssumeRole
      Policies:
        - PolicyName: sagemaker-standard
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Sid: Glue
                Effect: Allow
                Action:
                  - glue:GetConnections
                Resource: "*"
              - Sid: Logs
                Effect: Allow
                Action:
                  - logs:CreateLogStream
                  - logs:DescribeResourcePolicies
                Resource: "*"
              - Sid: SageMaker
                Effect: Allow
                Action:
                  - sagemaker:AddTags
                  - sagemaker:CreateApp
                  - sagemaker:CreatePresignedDomainUrl
                  - sagemaker:CreateSpace
                  - sagemaker:DeleteApp
                  - sagemaker:DeleteSpace
                  - sagemaker:DescribeApp
                  - sagemaker:DescribeDomain
                  - sagemaker:DescribeSpace
                  - sagemaker:DescribeUserProfile
                  - sagemaker:ListApps
                  - sagemaker:ListPartnerApps
                  - sagemaker:ListSpaces
                  - sagemaker:ListTags
                  - sagemaker:UpdateSpace
                Resource: "*"
              - Sid: S3
                Effect: Allow
                Action:
                  - s3:GetObject
                  - s3:PutObject
                  - s3:ListBucket
                Resource:
                  - !Sub "arn:${AWS::Partition}:s3:::${StudioBucket}"
                  - !Sub "arn:${AWS::Partition}:s3:::${StudioBucket}/*"
              - Sid: AllowGetIAMInfo
                Effect: Allow
                Action:
                  - iam:GetRole
                  - iam:GetRolePolicy
                  - iam:ListRoleTags
                Resource:
                  - "arn:aws:iam::*:role/*SageMakerExecutionRole*"
              - Sid: MarketplaceOperationsFromBedrockFor3pModels
                Effect: Allow
                Action:
                  - "aws-marketplace:Subscribe"
                  - "aws-marketplace:ViewSubscriptions"
                  - "aws-marketplace:Unsubscribe"
                Resource: "*"
                Condition:
                  StringEquals:
                    aws:CalledViaLast: "bedrock.amazonaws.com"
        - PolicyName: AgentCoreStarterToolkit
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Sid: IAMRoleManagement
                Effect: Allow
                Action:
                  - iam:CreateRole
                  - iam:DeleteRole
                  - iam:GetRole
                  - iam:PutRolePolicy
                  - iam:DeleteRolePolicy
                  - iam:AttachRolePolicy
                  - iam:DetachRolePolicy
                  - iam:TagRole
                  - iam:ListRolePolicies
                  - iam:ListAttachedRolePolicies
                Resource:
                  - !Sub "arn:${AWS::Partition}:iam::${AWS::AccountId}:role/*BedrockAgentCore*"
                  - !Sub "arn:${AWS::Partition}:iam::${AWS::AccountId}:role/service-role/*BedrockAgentCore*"
              - Sid: IAMNetworkServiceLinkedRoleCreation
                Effect: Allow
                Action:
                  - iam:CreateServiceLinkedRole
                Resource:
                  - !Sub "arn:${AWS::Partition}:iam::*:role/aws-service-role/network.bedrock-agentcore.amazonaws.com/AWSServiceRoleForBedrockAgentCoreNetwork"
                Condition:
                  StringLike:
                    iam:AWSServiceName: "network.bedrock-agentcore.amazonaws.com"
              - Sid: IAMIdentityServiceLinkedRoleCreation
                Effect: Allow
                Action:
                  - iam:CreateServiceLinkedRole
                Resource:
                  - !Sub "arn:${AWS::Partition}:iam::*:role/aws-service-role/runtime-identity.bedrock-agentcore.amazonaws.com/AWSServiceRoleForBedrockAgentCoreRuntimeIdentity"
                Condition:
                  StringLike:
                    iam:AWSServiceName: "runtime-identity.bedrock-agentcore.amazonaws.com"
              - Sid: CodeBuildProjectAccess
                Effect: Allow
                Action:
                  - codebuild:StartBuild
                  - codebuild:BatchGetBuilds
                  - codebuild:ListBuildsForProject
                  - codebuild:CreateProject
                  - codebuild:UpdateProject
                  - codebuild:BatchGetProjects
                Resource:
                  - !Sub "arn:${AWS::Partition}:codebuild:*:*:project/bedrock-agentcore-*"
                  - !Sub "arn:${AWS::Partition}:codebuild:*:*:project/bedrock-agentcore-*"
              - Sid: CodeBuildListAccess
                Effect: Allow
                Action:
                  - codebuild:ListProjects
                Resource: "*"
              - Sid: BedrockAgentCore
                Effect: Allow
                Action:
                  - bedrock-agentcore:CreateAgentRuntime
                  - bedrock-agentcore:CreateAgentRuntimeEndpoint
                  - bedrock-agentcore:CreateGatewayTarget
                  - bedrock-agentcore:CreateWorkloadIdentity
                  - bedrock-agentcore:DeleteAgentRuntime
                  - bedrock-agentcore:DeleteAgentRuntimeEndpoint
                  - bedrock-agentcore:DeleteGatewayTarget
                  - bedrock-agentcore:DeleteWorkloadIdentity
                  - bedrock-agentcore:GetAgentRuntime
                  - bedrock-agentcore:GetAgentRuntimeEndpoint
                  - bedrock-agentcore:GetGatewayTarget
                  - bedrock-agentcore:GetWorkloadIdentity
                  - bedrock-agentcore:ListAgentRuntimes
                  - bedrock-agentcore:ListGatewayTargets
                  - bedrock-agentcore:UpdateAgentRuntime
                  - bedrock-agentcore:UpdateAgentRuntimeEndpoint
                  - bedrock-agentcore:UpdateGatewayTarget
                  - bedrock-agentcore:UpdateWorkloadIdentity
                  - bedrock-agentcore:InvokeAgentRuntime
                  - bedrock-agentcore:SynchronizeGatewayTargets
                Resource: "*"
              - Sid: IAMPassRoleAccess
                Effect: Allow
                Action:
                  - "iam:PassRole"
                Resource:
                  - !Sub "arn:${AWS::Partition}:iam::*:role/AmazonBedrockAgentCore*"
                  - !Sub "arn:${AWS::Partition}:iam::*:role/service-role/AmazonBedrockAgentCore*"
              - Sid: CloudWatchLogsAccess
                Effect: Allow
                Action:
                  - "logs:GetLogEvents"
                  - "logs:DescribeLogGroups"
                  - "logs:DescribeLogStreams"
                Resource:
                  - !Sub "arn:${AWS::Partition}:logs:*:*:log-group:/aws/bedrock-agentcore/*"
                  - !Sub "arn:${AWS::Partition}:logs:*:*:log-group:/aws/codebuild/*"
              - Sid: CloudWatchLogsPutAccessTransactionSearch
                Effect: Allow
                Action:
                  - "logs:PutResourcePolicy"
                Resource:
                  - !Sub "arn:${AWS::Partition}:logs:${AWS::Region}:${AWS::AccountId}:log-group::log-stream"
              - Sid: S3Access
                Effect: Allow
                Action:
                  - "s3:GetObject"
                  - "s3:PutObject"
                  - "s3:ListBucket"
                  - "s3:CreateBucket"
                  - "s3:PutLifecycleConfiguration"
                Resource:
                  - !Sub "arn:${AWS::Partition}:s3:::bedrock-agentcore-*"
                  - !Sub "arn:${AWS::Partition}:s3:::bedrock-agentcore-*/*"
              - Sid: ECRRepositoryAccess
                Effect: Allow
                Action:
                  - "ecr:CreateRepository"
                  - "ecr:DescribeRepositories"
                  - "ecr:GetRepositoryPolicy"
                  - "ecr:InitiateLayerUpload"
                  - "ecr:CompleteLayerUpload"
                  - "ecr:PutImage"
                  - "ecr:UploadLayerPart"
                  - "ecr:BatchCheckLayerAvailability"
                  - "ecr:GetDownloadUrlForLayer"
                  - "ecr:BatchGetImage"
                  - "ecr:ListImages"
                  - "ecr:TagResource"
                Resource:
                  - !Sub "arn:${AWS::Partition}:ecr:*:*:repository/bedrock-agentcore-*"
              - Sid: ECRAuthorizationAccess
                Effect: Allow
                Action:
                  - "ecr:GetAuthorizationToken"
                Resource: "*"
        - PolicyName: Other
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Sid: Bedrock
                Effect: Allow
                Action:
                  - bedrock:InvokeModel
                  - bedrock:InvokeModelWithResponseStream
                Resource: "*"
              - Sid: SSM
                Effect: Allow
                Action:
                  - ssm:GetParameter
                Resource: "*"
              - Sid: STS
                Effect: Allow
                Action:
                  - sts:GetCallerIdentity
                Resource: "*"
              - Sid: XRay
                Effect: Allow
                Action:
                  - xray:GetIndexingRules
                  - xray:GetTraceSegmentDestination
                Resource: "*"
              - Sid: DynamoDb
                Effect: Allow
                Action:
                  - dynamodb:CreateTable
                  - dynamodb:DescribeTable
                  - dynamodb:GetItem
                  - dynamodb:PutItem
                  - dynamodb:Scan
                  - dynamodb:Query
                Resource:
                  - !GetAtt ResearchEvidenceTable.Arn
                  - !Sub "${ResearchEvidenceTable.Arn}/*"
              - Sid: CognitoIDP
                Effect: Allow
                Action:
                  - cognito-idp:ListResourceServers
                  - cognito-idp:DescribeResourceServer
                  - cognito-idp:ListIdentityProviders
                  - cognito-idp:ListUserPools
                Resource:
                  - !Sub arn:${AWS::Partition}:cognito-idp:${AWS::Region}:${AWS::AccountId}:userpool/*
              - Sid: AgentCoreMemory
                Effect: Allow
                Action:
                  - bedrock-agentcore:ListMemories
                  - bedrock-agentcore:ListMemoryRecords
                  - bedrock-agentcore:RetrieveMemoryRecords
                  - bedrock-agentcore:GetMemory
                  - bedrock-agentcore:GetMemoryRecord
                  - bedrock-agentcore:CreateEvent
                  - bedrock-agentcore:GetEvent
                  - bedrock-agentcore:ListEvents
                Resource:
                  - !Sub arn:${AWS::Partition}:bedrock-agentcore:${AWS::Region}:${AWS::AccountId}:memory/researchapp*
              - Sid: AgentCoreIdentity
                Effect: Allow
                Action:
                  - bedrock-agentcore:CreateOauth2CredentialProvider
                Resource:
                  - !Sub arn:${AWS::Partition}:bedrock-agentcore:${AWS::Region}:${AWS::AccountId}:token-vault/*
              - Sid: Secrets
                Effect: Allow
                Action:
                  - secretsmanager:CreateSecret
                Resource: "*"

  StudioDomain:
    Type: AWS::SageMaker::Domain
    DeletionPolicy: Retain # Will delete with CleanUpSageMaker custom resource instead
    UpdateReplacePolicy: Retain # Will delete with CleanUpSageMaker custom resource instead
    Properties:
      AppNetworkAccessType: PublicInternetOnly
      AuthMode: IAM
      DefaultUserSettings:
        ExecutionRole: !GetAtt SageMakerExecutionRole.Arn
      DomainName: !Ref DomainName
      SubnetIds: !GetAtt DefaultVpcFinder.SubnetIds
      VpcId: !GetAtt DefaultVpcFinder.VpcId

  UserProfile:
    Type: AWS::SageMaker::UserProfile
    DeletionPolicy: Retain # Will delete with CleanUpSageMaker custom resource instead
    UpdateReplacePolicy: Retain # Will delete with CleanUpSageMaker custom resource instead
    Properties:
      DomainId: !GetAtt StudioDomain.DomainId
      UserProfileName: !Ref UserProfileName
      UserSettings:
        ExecutionRole: !GetAtt SageMakerExecutionRole.Arn

  DefaultVpcFinder:
    Type: Custom::ResourceForFindingDefaultVpc
    Properties:
      ServiceToken: !GetAtt DefaultVPCSubnetsLambda.Arn

  DefaultVPCSubnetsLambdaRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
        - arn:aws:iam::aws:policy/AmazonVPCReadOnlyAccess

  DefaultVPCSubnetsLambda:
    Type: AWS::Lambda::Function
    Metadata:
      cfn_nag:
        rules_to_suppress:
          - id: W89
            reason: "Lambda function needs to query VPC information and does not require VPC deployment"
          - id: W92
            reason: "Reserved concurrent executions not required for infrequent CloudFormation custom resource"
    Properties:
      Runtime: python3.13
      Handler: index.handler
      MemorySize: 128
      Timeout: 15
      Architectures:
        - arm64
      Role: !GetAtt DefaultVPCSubnetsLambdaRole.Arn
      ReservedConcurrentExecutions: 1
      Code:
        ZipFile: |
          from boto3 import client
          import cfnresponse
          import logging
          import random

          logger = logging.getLogger()
          logger.setLevel(logging.INFO)

          ec2 = client('ec2')

          def handler(event, context):
              logger.debug(f'event: {event}')
              logger.debug(f'context: {context}')
              try:
                  if event['RequestType'] in ['Create', 'Update']:
                      # Get the default VPC
                      filter_vpc = [
                          {
                              'Name': 'is-default',
                              'Values': ['true']
                          }
                      ]
                      logger.debug(f'Calling describe_vpcs. Filter: {filter_vpc}')
                      describe_vpcs_response = ec2.describe_vpcs(Filters=filter_vpc)
                      logger.debug(f'Response: {describe_vpcs_response}')

                      vpcs = describe_vpcs_response['Vpcs']
                      logger.info(f'Found VPC: {vpcs}')

                      if not vpcs:
                          raise Exception('No default VPC found')

                      default_vpc_id = vpcs[0]['VpcId']

                      # Get subnets in the default VPC
                      filter_subnets = [
                          {
                              'Name': 'vpc-id',
                              'Values': [default_vpc_id]
                          }
                      ]
                      logger.debug(f'Calling describe_subnets. Filter: {filter_subnets}')
                      describe_subnet_response = ec2.describe_subnets(Filters=filter_subnets)
                      logger.debug(f'Response: {describe_subnet_response}')
                      subnets = describe_subnet_response['Subnets']
                      logger.info(f'Found subnets: {subnets}')

                      subnet_ids = [subnet['SubnetId'] for subnet in subnets]
                      logger.debug(f'Subnet IDs: {subnet_ids}')

                      subnet_count = event['ResourceProperties'].get('SubnetCount')
                      if subnet_count:
                          # shuffle subnet_ids list
                          random.shuffle(subnet_ids)
                          # take the first subnet_count elements
                          subnet_ids = subnet_ids[:int(subnet_count)]
                          logger.info(f'Filtered {subnet_count} Subnet IDs: {subnet_ids}')

                      response_data = {
                          'SubnetIds': subnet_ids,
                          'VpcId': default_vpc_id
                      }

                      logger.info(f'ResponseData: {response_data}')

                      cfnresponse.send(event, context, cfnresponse.SUCCESS, responseData = response_data, reason = 'OK')
                  else:
                      cfnresponse.send(event, context, cfnresponse.SUCCESS, responseData = {}, reason = 'No action to take')
              except Exception as e:
                  logger.error(f'Error processing request: {e}')
                  cfnresponse.send(event, context, cfnresponse.FAILED, {})

  StudioDomainURIParameter:
    Type: AWS::SSM::Parameter
    Properties:
      Name: /deep-research-workshop/sagemaker-studio-domain-uri
      Description: URI of the Amazon SageMaker Studio Domain
      Type: String
      Value: !Sub https://${AWS::Region}.console.aws.amazon.com/sagemaker/home?region=${AWS::Region}#/studio/open/${StudioDomain}/${UserProfileName}

  ###################################################################
  # Custom Resource: Fully delete SageMaker AI resources
  ###################################################################

  CleanUpSageMaker:
    Type: Custom::ResourceForCleaningUpSageMaker
    Properties:
      ServiceToken: !GetAtt CleanUpSageMakerLambda.Arn
      DomainId: !Ref StudioDomain
      S3Bucket: !Ref StudioBucket

  CleanUpSageMakerLambdaRole:
    Type: "AWS::IAM::Role"
    Metadata:
      cfn_nag:
        rules_to_suppress:
          - id: W11
            reason: "Wildcard permissions required for SageMaker resource discovery and cleanup operations"
          - id: W76
            reason: "High SPCM acceptable for cleanup role with broad permissions for resource deletion"
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
            Action:
              - "sts:AssumeRole"
      Policies:
        - PolicyName: LambdaPolicies
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Sid: GetSageMakerExecutionRoleforCleanup
                Effect: Allow
                Action: iam:GetRole
                Resource: !GetAtt SageMakerExecutionRole.Arn
              - Sid: ListSageMaker
                Effect: Allow
                Action:
                  - sagemaker:ListApps
                  - sagemaker:ListSpaces
                  - sagemaker:ListUserProfiles
                  - sagemaker:ListDomains
                  - sagemaker:ListEndpoints
                Resource: "*"
              - Sid: CleanUpSageMakerApps
                Effect: Allow
                Action:
                  - sagemaker:DeleteApp
                Resource:
                  - !Sub arn:${AWS::Partition}:sagemaker:${AWS::Region}:${AWS::AccountId}:app/${StudioDomain}/*
              - Sid: CleanUpSageMakerSpaces
                Effect: Allow
                Action:
                  - sagemaker:DeleteSpace
                Resource:
                  - !Sub arn:${AWS::Partition}:sagemaker:${AWS::Region}:${AWS::AccountId}:space/${StudioDomain}/*
              - Sid: CleanUpSageMakerUserProfile
                Effect: Allow
                Action:
                  - sagemaker:DeleteUserProfile
                Resource:
                  - !Sub arn:${AWS::Partition}:sagemaker:${AWS::Region}:${AWS::AccountId}:user-profile/${StudioDomain}/*
              - Sid: CleanUpSageMakerDomains
                Effect: Allow
                Action:
                  - sagemaker:DeleteDomain
                Resource:
                  - !Sub arn:${AWS::Partition}:sagemaker:${AWS::Region}:${AWS::AccountId}:domain/${StudioDomain}
              - Sid: CleanUpSageMakerEndpoints
                Effect: Allow
                Action:
                  - sagemaker:DeleteEndpoint
                Resource:
                  - !Sub arn:${AWS::Partition}:sagemaker:${AWS::Region}:${AWS::AccountId}:endpoint/*
              - Sid: CleanUpSageMakerS3Bucket
                Effect: Allow
                Action:
                  - s3:ListBucket
                  - s3:ListBucketVersions
                Resource:
                  - !Sub arn:${AWS::Partition}:s3:::${StudioBucket}
              - Sid: CleanUpSageMakerS3BucketObjects
                Effect: Allow
                Action:
                  - s3:GetObject
                  - s3:GetObjectVersion
                  - s3:DeleteObject
                  - s3:DeleteObjectVersion
                Resource:
                  - !Sub arn:${AWS::Partition}:s3:::${StudioBucket}/*
      ManagedPolicyArns:
        - "arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole"

  CleanUpSageMakerLambda:
    Type: AWS::Lambda::Function
    DependsOn: StudioDomain
    Metadata:
      cfn_nag:
        rules_to_suppress:
          - id: W89
            reason: "Lambda function performs cleanup operations and does not require VPC deployment"
    Properties:
      ReservedConcurrentExecutions: 5
      Code:
        ZipFile: |
          # Function: CFCleanUpSageMaker
          # Purpose:  Clean up sagemaker
          import boto3
          from botocore.config import Config
          import cfnresponse
          import logging
          from time import sleep
          LOGGER = logging.getLogger()
          LOGGER.setLevel(logging.INFO)
          def emptyBucket(bucket_name, boto_session):
              LOGGER.info(f"Deleting objects from {bucket_name}")
              bucket = boto_session.resource("s3").Bucket(bucket_name)
              bucket.objects.filter().delete()
              return None
          def deleteActiveSageMakerEndpoints(sm):
              endpoints = sm.list_endpoints()
              active_endpoints = [e.get("EndpointName") for e in endpoints.get("Endpoints")]
              for endpoint in active_endpoints:
                  LOGGER.info(f"Deleting Endpoint {endpoint}")
                  sm.delete_endpoint(EndpointName=endpoint)
              while len(active_endpoints) > 0:
                  sleep(5)
                  endpoints = sm.list_endpoints()
                  active_endpoints = [e.get("EndpointName") for e in endpoints.get("Endpoints")]
              return None
          def deleteAllRunningSageMakerApps(domain_id, sm):
              apps = sm.list_apps(DomainIdEquals=domain_id)
              active_apps = [
                  app for app in apps["Apps"] if app.get("Status") not in ["Deleted", "Deleting", "PendingCheckout"]
              ]
              for a in active_apps:
                  LOGGER.info(f'Deleting app {a["AppName"]}')
                  response = sm.delete_app(
                      DomainId=a["DomainId"],
                      AppType=a["AppType"],
                      AppName=a["AppName"],
                      SpaceName=a["SpaceName"]
                  )
              while len(active_apps) > 0:
                  sleep(5)
                  apps = sm.list_apps(DomainIdEquals=domain_id)
                  active_apps = [
                      app for app in apps["Apps"] if app.get("Status") not in ["Deleted"]
                  ]
              return None
          def deleteAllRunningSageMakerSpaces(domain_id, sm):
              spaces = sm.list_spaces(DomainIdEquals=domain_id)
              active_spaces = [
                  space for space in spaces["Spaces"] if space.get("Status") not in ["Deleted", "Deleting", "PendingCheckout"]
              ]
              for a in active_spaces:
                  LOGGER.info(f'Deleting space {a["SpaceName"]}')
                  sm.delete_space(
                      DomainId=a["DomainId"],
                      SpaceName=a["SpaceName"],
                  )
              while len(active_spaces) > 0:
                  sleep(5)
                  spaces = sm.list_spaces(DomainIdEquals=domain_id)
                  active_spaces = [
                      space for space in spaces["Spaces"] if space.get("Status") not in ["Deleted"]
                  ]
              return None              
          def deleteUserProfiles(domain_id, sm):
              user_profiles = sm.list_user_profiles(DomainIdEquals=domain_id)["UserProfiles"]
              for profile in user_profiles:
                  LOGGER.info(f"Deleting User Profile {profile}")
                  sm.delete_user_profile(
                      DomainId=domain_id, UserProfileName=profile["UserProfileName"]
                  )
              while user_profiles:
                  sleep(5)
                  user_profiles = sm.list_user_profiles(DomainIdEquals=domain_id)["UserProfiles"]
              return None
          def deleteSageMakerDomainPlusEFS(domain_id, sm):
              LOGGER.info(f"Deleting SageMaker Domain {domain_id}")
              sm.delete_domain(
                  DomainId=domain_id, RetentionPolicy={"HomeEfsFileSystem": "Delete"}
              )
              domains = sm.list_domains()
              while domain_id in [domain.get("DomainId") for domain in domains["Domains"]]:
                  sleep(5)
                  domains = sm.list_domains()
              return None
          def lambda_handler(event, context):
              try:
                  LOGGER.info("REQUEST RECEIVED:\n %s", event)
                  retry_config = Config(
                      retries={
                          'max_attempts': 5,
                          'mode': 'standard'
                      }
                  )

                  boto_session = boto3.session.Session()
                  sm = boto_session.client("sagemaker", config=retry_config)
                  if event["RequestType"] == "Create":
                      LOGGER.info("CREATE!")
                      cfnresponse.send(
                          event,
                          context,
                          cfnresponse.SUCCESS,
                          {"response": "Resource creation successful!"},
                      )
                  elif event["RequestType"] == "Update":
                      LOGGER.info("UPDATE!")
                      cfnresponse.send(
                          event,
                          context,
                          cfnresponse.SUCCESS,
                          {"response": "Resource update successful!"},
                      )
                  elif event["RequestType"] == "Delete":
                      LOGGER.info("DELETE!")
                      domain_id = event["ResourceProperties"]["DomainId"]
                      LOGGER.info("Emptying S3 Bucket")
                      emptyBucket(event["ResourceProperties"]["S3Bucket"], boto_session)
                      LOGGER.info("Deleting SageMaker Endpoints")
                      deleteActiveSageMakerEndpoints(sm)
                      LOGGER.info("Deleting SageMaker Apps")
                      deleteAllRunningSageMakerApps(domain_id, sm)
                      LOGGER.info("Deleting SageMaker Spaces")
                      deleteAllRunningSageMakerSpaces(domain_id, sm)
                      LOGGER.info("Deleting SageMaker User Profiles")
                      deleteUserProfiles(domain_id, sm)
                      LOGGER.info("Deleting SageMaker Domain")
                      deleteSageMakerDomainPlusEFS(domain_id, sm)
                      cfnresponse.send(
                          event,
                          context,
                          cfnresponse.SUCCESS,
                          {"response": "Resource deletion successful!"},
                      )
                  else:
                      LOGGER.info("FAILED!")
                      cfnresponse.send(
                          event,
                          context,
                          cfnresponse.FAILED,
                          {"response": "Unexpected event received from CloudFormation"},
                      )
              except Exception as e:
                  LOGGER.info("FAILED!")
                  LOGGER.info(e)
                  cfnresponse.send(
                      event,
                      context,
                      cfnresponse.FAILED,
                      {"response": "Exception during processing"},
                  )
      Description: Clean up Sagemaker
      Handler: index.lambda_handler
      MemorySize: 128
      Role: !GetAtt CleanUpSageMakerLambdaRole.Arn
      Runtime: python3.13
      Timeout: 600

  CreateCodeRepositorySuggestion:
    Type: Custom::ResourceFoCreatingCodeRepository
    Properties:
      ServiceToken: !GetAtt CreateCodeRepositorySuggestionLambda.Arn
      DomainId: !Ref StudioDomain
      CodeRepository: !Ref CodeRepository

  CreateCodeRepositorySuggestionRole:
    Type: "AWS::IAM::Role"
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
            Action:
              - "sts:AssumeRole"
      Policies:
        - PolicyName: LambdaPolicies
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Sid: AddCodeRepo
                Effect: Allow
                Action:
                  - sagemaker:UpdateDomain
                Resource: !GetAtt StudioDomain.DomainArn
      ManagedPolicyArns:
        - "arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole"

  CreateCodeRepositorySuggestionLambda:
    Type: AWS::Lambda::Function
    DependsOn: StudioDomain
    Metadata:
      cfn_nag:
        rules_to_suppress:
          - id: W89
            reason: "Lambda function performs SageMaker configuration and does not require VPC deployment"
          - id: W92
            reason: "Reserved concurrent executions not required for infrequent CloudFormation custom resource"
    Properties:
      ReservedConcurrentExecutions: 1
      Code:
        ZipFile: |
          # Function: CreateCodeRepositorySuggestionLambda
          # Purpose:  Create Code Repository suggestion in SageMaker
          import boto3
          import cfnresponse
          import logging
          from time import sleep
          LOGGER = logging.getLogger()
          LOGGER.setLevel(logging.INFO)

          def create_code_repository(domain_id, repo_url, sagemaker_boto_client):
              response = sagemaker_boto_client.update_domain(
                  DomainId=domain_id,
                  DefaultUserSettings={
                      "JupyterServerAppSettings": {
                          "CodeRepositories": [{"RepositoryUrl": repo_url}]
                      },
                      "JupyterLabAppSettings": {
                          "CodeRepositories": [{"RepositoryUrl": repo_url}]
                      },
                  },
              )
              return None

          def lambda_handler(event, context):
              try:
                  LOGGER.info("REQUEST RECEIVED:\n %s", event)
                  boto_session = boto3.session.Session()
                  sm = boto_session.client("sagemaker")
                  if event["RequestType"] == "Create":
                      LOGGER.info("CREATE!")
                      create_code_repository(event["ResourceProperties"]["DomainId"], event["ResourceProperties"]["CodeRepository"], sm)
                      cfnresponse.send(
                          event,
                          context,
                          cfnresponse.SUCCESS,
                          {"response": "Resource creation successful!"},
                      )
                  elif event["RequestType"] == "Update":
                      LOGGER.info("UPDATE!")
                      cfnresponse.send(
                          event,
                          context,
                          cfnresponse.SUCCESS,
                          {"response": "Resource update successful!"},
                      )
                  elif event["RequestType"] == "Delete":
                      LOGGER.info("DELETE!")
                      cfnresponse.send(
                          event,
                          context,
                          cfnresponse.SUCCESS,
                          {"response": "Resource deletion successful!"},
                      )
                  else:
                      LOGGER.info("FAILED!")
                      cfnresponse.send(
                          event,
                          context,
                          cfnresponse.FAILED,
                          {"response": "Unexpected event received from CloudFormation"},
                      )
              except Exception as e:
                  LOGGER.info("FAILED!")
                  LOGGER.info(e)
                  cfnresponse.send(
                      event,
                      context,
                      cfnresponse.FAILED,
                      {"response": "Exception during processing"},
                  )
      Description: Create code repository
      Handler: index.lambda_handler
      MemorySize: 128
      Role: !GetAtt CreateCodeRepositorySuggestionRole.Arn
      Runtime: python3.13
      Timeout: 5

  CodeBuildServiceRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: Allow
            Principal:
              Service: codebuild.amazonaws.com
            Action: "sts:AssumeRole"
      Policies:
        - PolicyName: CodeBuildServicePolicy
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Sid: S3BucketAccess
                Effect: Allow
                Action:
                  - "s3:ListBucket"
                Resource: !Sub "arn:${AWS::Partition}:s3:::${StudioBucket}"
              - Sid: S3ObjectAccess
                Effect: Allow
                Action:
                  - "s3:GetObject"
                  - "s3:PutObject"
                Resource: !Sub "arn:${AWS::Partition}:s3:::${StudioBucket}/build/*"
              - Sid: CloudWatchLogsAccess
                Effect: Allow
                Action:
                  - "logs:CreateLogGroup"
                  - "logs:CreateLogStream"
                  - "logs:PutLogEvents"
                Resource: !Sub "arn:${AWS::Partition}:logs:${AWS::Region}:${AWS::AccountId}:log-group:/aws/codebuild/${CodeBuildProjectName}*"
              - Sid: SSMParameterAccess
                Effect: Allow
                Action:
                  - "ssm:GetParameter"
                  - "ssm:GetParameters"
                Resource: !Sub "arn:${AWS::Partition}:ssm:${AWS::Region}:${AWS::AccountId}:parameter/deep-research-workshop/*"

  TriggerBuildRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: "sts:AssumeRole"
      ManagedPolicyArns:
        - "arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole"
      Policies:
        - PolicyName: TriggerCodeBuildPolicy
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: Allow
                Action:
                  - "codebuild:StartBuild"
                  - "codebuild:BatchGetBuilds"
                Resource: !GetAtt CodeBuildProject.Arn

  TriggerBuildFunction:
    Type: AWS::Lambda::Function
    Properties:
      Runtime: python3.12
      Handler: index.handler
      Role: !GetAtt TriggerBuildRole.Arn
      Timeout: 900
      Code:
        ZipFile: |
          import json
          import boto3
          import cfnresponse
          import time

          codebuild = boto3.client('codebuild')

          def handler(event, context):
              print(f"Event: {json.dumps(event)}")
              
              try:
                  request_type = event['RequestType']
                  project_name = event['ResourceProperties']['ProjectName']
                  
                  if request_type == 'Create':
                      print(f"Starting build for project: {project_name}")
                      response = codebuild.start_build(projectName=project_name)
                      build_id = response['build']['id']
                      print(f"Build started: {build_id}")
                      
                      # Wait for build to complete
                      print(f"Waiting for build {build_id} to complete...")
                      max_wait_time = 840  # 14 minutes (leave buffer for Lambda timeout)
                      start_time = time.time()
                      poll_interval = 10
                      
                      while True:
                          elapsed = time.time() - start_time
                          if elapsed > max_wait_time:
                              error_msg = f"Build timed out after {max_wait_time} seconds"
                              print(error_msg)
                              cfnresponse.send(event, context, cfnresponse.FAILED, {'Error': error_msg})
                              return
                          
                          build_response = codebuild.batch_get_builds(ids=[build_id])
                          build = build_response['builds'][0]
                          build_status = build['buildStatus']
                          
                          print(f"Build status: {build_status} (elapsed: {int(elapsed)}s)")
                          
                          if build_status == 'SUCCEEDED':
                              print(f"Build completed successfully: {build_id}")
                              cfnresponse.send(event, context, cfnresponse.SUCCESS, {
                                  'BuildId': build_id,
                                  'BuildStatus': build_status
                              })
                              return
                          elif build_status in ['FAILED', 'FAULT', 'TIMED_OUT', 'STOPPED']:
                              error_msg = f"Build {build_status.lower()}: {build_id}"
                              print(error_msg)
                              cfnresponse.send(event, context, cfnresponse.FAILED, {
                                  'Error': error_msg,
                                  'BuildId': build_id,
                                  'BuildStatus': build_status
                              })
                              return
                          
                          # Build still in progress
                          time.sleep(poll_interval)
                  else:
                      print(f"No action needed for {request_type}")
                      cfnresponse.send(event, context, cfnresponse.SUCCESS, {
                          'BuildId': 'N/A',
                          'BuildStatus': 'SKIPPED'
                      })
                      
              except Exception as e:
                  print(f"Error: {str(e)}")
                  cfnresponse.send(event, context, cfnresponse.FAILED, {'Error': str(e)})

  CodeBuildProject:
    Type: AWS::CodeBuild::Project
    Properties:
      Name: !Ref CodeBuildProjectName
      Description: "Build workshop content from GitHub repository"
      ServiceRole: !GetAtt CodeBuildServiceRole.Arn
      Artifacts:
        Type: NO_ARTIFACTS
      Environment:
        Type: LINUX_CONTAINER
        ComputeType: BUILD_GENERAL1_SMALL
        Image: "aws/codebuild/standard:7.0"
      Source:
        Type: GITHUB
        Location: !Ref CodeBuildGitHubRepository
        GitCloneDepth: 1
        BuildSpec: |
          version: 0.2
          phases:
            pre_build:
              commands:
                - echo "Retrieving S3 bucket name from SSM"
                - export S3_BUCKET_NAME=$(aws ssm get-parameter --name /deep-research-workshop/s3-bucket-name --query Parameter.Value --output text)
                - echo "Target bucket is $S3_BUCKET_NAME"
            build:
              commands:
                - echo "Copying api_spec.json to S3"
                - aws s3 cp infrastructure/lambda/api_spec.json s3://$S3_BUCKET_NAME/build/api_spec.json
                - echo "File copied successfully"
                - echo "Packaging Lambda function"
                - cd infrastructure/lambda
                - 'pip install -r requirements.txt --platform manylinux2014_aarch64 --target ./packaging/_dependencies --only-binary=:all:'
                - python package_for_lambda.py
                - echo "Uploading Lambda packages to S3"
                - aws s3 cp packaging/app.zip s3://$S3_BUCKET_NAME/build/app.zip
                - aws s3 cp packaging/dependencies.zip s3://$S3_BUCKET_NAME/build/dependencies.zip
                - echo "Lambda packages uploaded successfully"
      SourceVersion: !Ref CodeBuildGitHubBranch
      TimeoutInMinutes: 10
      LogsConfig:
        CloudWatchLogs:
          Status: ENABLED

  TriggerInitialBuild:
    Type: Custom::TriggerBuild
    Properties:
      ServiceToken: !GetAtt TriggerBuildFunction.Arn
      ProjectName: !Ref CodeBuildProject

Outputs:
  StudioDomainURI:
    Description: URI of the Amazon SageMaker Studio Domain
    Value: !Sub https://${AWS::Region}.console.aws.amazon.com/sagemaker/home?region=${AWS::Region}#/studio/open/${StudioDomain}/${UserProfileName}
  S3BucketName:
    Description: Amazon S3 bucket name for deep research workshop
    Value: !Ref StudioBucket
  DynamoDBTableName:
    Description: DynamoDB table name for deep research workshop
    Value: !Ref ResearchEvidenceTable
  DynamoDBTableArn:
    Description: DynamoDB table ARN for deep research workshop
    Value: !GetAtt ResearchEvidenceTable.Arn
  CodeBuildProjectName:
    Description: "Name of the CodeBuild project"
    Value: !Ref CodeBuildProject
    Export:
      Name: !Sub "${AWS::StackName}-CodeBuildProject"
  CodeBuildProjectArn:
    Description: "ARN of the CodeBuild project"
    Value: !GetAtt CodeBuildProject.Arn
    Export:
      Name: !Sub "${AWS::StackName}-CodeBuildProjectArn"
  CodeBuildServiceRoleArn:
    Description: "ARN of the CodeBuild service role"
    Value: !GetAtt CodeBuildServiceRole.Arn
    Export:
      Name: !Sub "${AWS::StackName}-CodeBuildServiceRoleArn"
  InitialBuildId:
    Description: "Build ID of the initial triggered build"
    Value: !GetAtt TriggerInitialBuild.BuildId
    Export:
      Name: !Sub "${AWS::StackName}-InitialBuildId"
  InitialBuildStatus:
    Description: "Status of the initial triggered build"
    Value: !GetAtt TriggerInitialBuild.BuildStatus
