{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d534971-cb20-4752-9331-a3f98339eced",
   "metadata": {},
   "source": [
    "# Multi-Agent Orchestration\n",
    "\n",
    "In this notebook, you'll create a team of agents that can create detailed research reports.\n",
    "\n",
    "Here's how this will work:\n",
    "\n",
    "1. User ask question to lead agent.\n",
    "2. Lead agent (LA) decomposes question and creates report outline.\n",
    "3. Lead agent calls research agent (RA) with instructions for section 1.\n",
    "4. RA examines instructions and calls `search_pmc` and `gather_evidence` tools multiple times. Every time `gather_evidence` finishes, it saves an evidence record to DynamoDB.\n",
    "6. RA returns a research summary and source information to LA.\n",
    "7. LA updates outline with information from RA.\n",
    "8. Repeat steps 3-7 for all outline sections.\n",
    "9. Once research is complete, LA submits outline to generate_report tool (GR).\n",
    "10. GR retrieves evidence records from DynamoDB and generates report text with inline citations using Claude citation API.\n",
    "11. GR reports completion to LA\n",
    "12. LA writes final report to a file and shares contents with user.\n",
    "\n",
    "## 1. Prerequisites\n",
    "\n",
    "- Python 3.12 or later\n",
    "- AWS account configured with appropriate permissions\n",
    "- Access to the Anthropic Claude 3.7 Sonnet model in Amazon Bedrock\n",
    "- Basic understanding of Python programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722465ef-f70b-48fc-9b78-d4d8a49f30b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pip install -U -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d16ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ID = \"global.anthropic.claude-sonnet-4-20250514-v1:0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136e048e",
   "metadata": {},
   "source": [
    "## 2. Define PMC Research Agent\n",
    "\n",
    "This agent will be similar to the gather evidence agent we created in notebook 2, but with a change in how the evidence is stored. To avoid the \"game of telephone\" problem, we are going to deterministically store the gathered evidence in a DynamoDB table. This is a big advantage to building AI agents on AWS - they can leverage any of the 200+ services to store and process data.\n",
    "\n",
    "Let's test out the updated tool to see how it works.\n",
    "\n",
    "First, we create a DynamoDB table, with `toolUseId` as the primary key and `pmcid` as a global secondary id. This gives us the flexibility to extract evidence records either by tool use or paper. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b279954",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "dynamodb = boto3.resource(\"dynamodb\")\n",
    "\n",
    "# Check if table exists\n",
    "table_name = \"deep-research-evidence\"\n",
    "try:\n",
    "    table = dynamodb.Table(table_name)\n",
    "    table.load()\n",
    "    print(f\"Table '{table_name}' already exists\")\n",
    "except:\n",
    "    # Create table if it doesn't exist\n",
    "    table = dynamodb.create_table(\n",
    "        TableName=table_name,\n",
    "        KeySchema=[{\"AttributeName\": \"evidence_id\", \"KeyType\": \"HASH\"}],\n",
    "        AttributeDefinitions=[\n",
    "            {\"AttributeName\": \"evidence_id\", \"AttributeType\": \"S\"},\n",
    "            {\"AttributeName\": \"source\", \"AttributeType\": \"S\"},\n",
    "        ],\n",
    "        GlobalSecondaryIndexes=[\n",
    "            {\n",
    "                \"IndexName\": \"source_index\",\n",
    "                \"KeySchema\": [{\"AttributeName\": \"source\", \"KeyType\": \"HASH\"}],\n",
    "                \"Projection\": {\"ProjectionType\": \"ALL\"},\n",
    "            }\n",
    "        ],\n",
    "        BillingMode=\"PAY_PER_REQUEST\",\n",
    "    )\n",
    "\n",
    "    table.wait_until_exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ca42d2",
   "metadata": {},
   "source": [
    "Next, we directly invoke the updated `gather_evidence` tool and pass the db table name as an environment variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d665d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from strands import Agent\n",
    "from search_pmc import search_pmc_tool\n",
    "from gather_evidence_ddb import gather_evidence_tool\n",
    "import os\n",
    "\n",
    "os.environ[\"EVIDENCE_TABLE_NAME\"] = table_name\n",
    "\n",
    "MODEL_ID = \"global.anthropic.claude-sonnet-4-20250514-v1:0\"\n",
    "agent = Agent(tools=[gather_evidence_tool], model=MODEL_ID)\n",
    "\n",
    "# Send a message to the agent\n",
    "agent.tool.gather_evidence_tool(\n",
    "    pmc_id=\"PMC9438179\",\n",
    "    question=\"How safe and effective are GLP-1 drugs for long term use?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c5870c",
   "metadata": {},
   "source": [
    "Let's look at the new records in our db table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be57396",
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamodb = boto3.resource(\"dynamodb\")\n",
    "\n",
    "# Check if table exists\n",
    "table_name = \"deep-research-evidence\"\n",
    "table = dynamodb.Table(table_name)\n",
    "\n",
    "records = [record for record in table.scan().get(\"Items\")]\n",
    "records"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd36be0",
   "metadata": {},
   "source": [
    "We can also query for a records from a specific PMC ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ee6ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from boto3.dynamodb.conditions import Key\n",
    "\n",
    "example_pmc_id = records[0][\"source\"]\n",
    "print(example_pmc_id)\n",
    "\n",
    "dynamodb = boto3.resource(\"dynamodb\")\n",
    "table_name = \"deep-research-evidence\"\n",
    "table = dynamodb.Table(table_name)\n",
    "\n",
    "\n",
    "response = table.query(\n",
    "    IndexName=\"source_index\", KeyConditionExpression=Key(\"source\").eq(example_pmc_id)\n",
    ")\n",
    "example_db_records = response.get(\"Items\")\n",
    "example_db_records"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620c7d9d",
   "metadata": {},
   "source": [
    "Let's incorporate our tool into a new `pmc_research_agent` definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba23226",
   "metadata": {},
   "outputs": [],
   "source": [
    "from strands import Agent\n",
    "from search_pmc import search_pmc_tool\n",
    "from gather_evidence_ddb import gather_evidence_tool\n",
    "import os\n",
    "\n",
    "MODEL_ID = \"global.anthropic.claude-sonnet-4-20250514-v1:0\"\n",
    "QUERY = \"How safe and effective are GLP-1 drugs for long term use?\"\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"You are a life science research assistant. When given a scientific question, follow this process:\n",
    "\n",
    "1. Use search_pmc_tool to find highly-cited papers. Search broadly first, then narrow down. Use temporal filters like \"last 2 years\"[dp] for recent work.\n",
    "2. Identify the PMC IDs of the most relevant papers, then submit each ID and the query to the gather_evidence_tool.\n",
    "3. Generate a concise answer to the question based on the most relevant evidence, followed by a list of the associated `evidence_id` values.\n",
    "\"\"\"\n",
    "\n",
    "os.environ[\"EVIDENCE_TABLE_NAME\"] = table_name\n",
    "\n",
    "# Initialize your agent\n",
    "pmc_research_agent = Agent(\n",
    "    system_prompt=SYSTEM_PROMPT,\n",
    "    tools=[search_pmc_tool, gather_evidence_tool],\n",
    "    model=MODEL_ID,\n",
    ")\n",
    "\n",
    "# Send a message to the agent\n",
    "response = pmc_research_agent(QUERY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd264d1",
   "metadata": {},
   "source": [
    "Now let's view the updated records in our evidence table again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2261dd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamodb = boto3.resource(\"dynamodb\")\n",
    "\n",
    "table_name = \"deep-research-evidence\"\n",
    "table = dynamodb.Table(table_name)\n",
    "\n",
    "records = [record for record in table.scan().get(\"Items\")]\n",
    "records"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873da989",
   "metadata": {},
   "source": [
    "We'll use our `pmc_research_agent` again later in this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6cf0ae",
   "metadata": {},
   "source": [
    "## 3. Define Technical Writing Agent\n",
    "\n",
    "Next, we'll build our writing agent. This agent will take in a question and evidence references and use the Anthropic Claude citations API to create a cited report. Let's test how this works with the Amazon Bedrock InvokeModel API \n",
    "\n",
    "Ref: https://docs.claude.com/en/docs/build-with-claude/citations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31141f9f",
   "metadata": {},
   "source": [
    "### 3.1. Explore Anthropic Claude Citations API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393abd8f",
   "metadata": {},
   "source": [
    "Here is an example of how to use the Claude citations API through a Bedrock InvokeModel call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa47639b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "bedrock_client = boto3.client(\"bedrock-runtime\")\n",
    "\n",
    "example_request = {\n",
    "    \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"document\",\n",
    "                    \"source\": {\n",
    "                        \"type\": \"text\",\n",
    "                        \"media_type\": \"text/plain\",\n",
    "                        \"data\": \"Based on the available context, specific recommendations for managing gastrointestinal adverse events during GLP-1 receptor agonist (GLP-1 RA) therapy include several key strategies. Management emphasizes comprehensive patient education, initiating treatment with low starting doses, and implementing gradual dose titration to minimize adverse events (Gorgojo2023 chunk 2). Dietary adjustments and ongoing monitoring are also essential components of the management approach (Gorgojo2023 chunk 2).\\n\\nRegarding clinical experience with long-term safety, GI adverse events occur in 40-85% of patients receiving GLP-1 RAs, but these events are typically mild and transient in nature (Gorgojo2023 chunk 2). The adverse events generally resolve following dose escalation, indicating that patients can adapt to therapy over time (Gorgojo2023 chunk 2). \\n\\nLong-term safety data demonstrate a favorable profile, with most events classified as non-serious and low rates of permanent treatment discontinuation (Gorgojo2023 chunk 2). This clinical experience supports the overall safety profile of GLP-1 RAs for long-term use (Gorgojo2023 chunk 2). The combination of appropriate management strategies and the generally mild, self-limiting nature of GI adverse events allows most patients to continue therapy successfully over extended periods.\",\n",
    "                    },\n",
    "                    \"title\": \"PMC9821052\",\n",
    "                    \"citations\": {\"enabled\": True},\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"document\",\n",
    "                    \"source\": {\n",
    "                        \"type\": \"text\",\n",
    "                        \"media_type\": \"text/plain\",\n",
    "                        \"data\": \"Long-term GLP-1 receptor agonist therapy demonstrates sustained efficacy in maintaining glycemic control and promoting weight loss (Zheng2024 chunk 55). However, therapeutic effectiveness may plateau over extended treatment periods, with studies indicating this limitation is associated with increased orbitofrontal reward activation, as observed with liraglutide (Zheng2024 chunk 55).\\n\\nThe adverse event profile is predominantly gastrointestinal, with nausea and vomiting representing the most common side effects (Zheng2024 chunk 55). Serious but rare adverse events include pancreatitis and gallbladder disease (Zheng2024 chunk 55).\\n\\nSeveral absolute contraindications exist for long-term GLP-1 receptor agonist use. Patients with a personal or family history of medullary thyroid carcinoma should not receive these agents (Zheng2024 chunk 55). Multiple endocrine neoplasia type 2 (MEN 2) also represents a contraindication (Zheng2024 chunk 55). Additionally, severe gastrointestinal disorders preclude the use of these medications (Zheng2024 chunk 55).\\n\\nThe safety and efficacy profile supports long-term use in appropriate patients, though careful patient selection is essential given the specific contraindications, particularly those related to thyroid malignancy risk and pre-existing gastrointestinal pathology.\",\n",
    "                    },\n",
    "                    \"title\": \"PMC9821052\",\n",
    "                    \"citations\": {\"enabled\": True},\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"What is the long-term safety profile and effectiveness of GLP-1 receptor agonists? What are the main adverse events and contraindications for long-term use?\",\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    \"max_tokens\": 1024,\n",
    "}\n",
    "\n",
    "response = bedrock_client.invoke_model(\n",
    "    modelId=\"us.anthropic.claude-sonnet-4-20250514-v1:0\",\n",
    "    contentType=\"application/json\",\n",
    "    accept=\"application/json\",\n",
    "    body=json.dumps(example_request),\n",
    ")\n",
    "\n",
    "response_body = json.loads(response[\"body\"].read())\n",
    "\n",
    "print(response_body.get(\"content\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73abb879",
   "metadata": {},
   "source": [
    "We can now format the response into a citated output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef9effd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_cited_response(response_content: dict) -> None:\n",
    "    citations = []\n",
    "    for content_item in response_content:\n",
    "        print(content_item.get(\"text\"), end=\"\")\n",
    "        for citation in content_item.get(\"citations\", []):\n",
    "            title = citation.get(\"document_title\")\n",
    "            if title not in citations:\n",
    "                citations.append(title)\n",
    "            print(f\" ({citations.index(title)+1})\", end=\"\")\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"## References\")\n",
    "    for i, title in enumerate(citations, start=1):\n",
    "        print(f\"{i}. https://www.ncbi.nlm.nih.gov/pmc/articles/{title}\")\n",
    "    return None\n",
    "\n",
    "\n",
    "print_cited_response(response_body.get(\"content\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90d4b1e",
   "metadata": {},
   "source": [
    "### 3.2. Create generate_report tool\n",
    "\n",
    "We've provided a Strands tool definition that incorporates this code in `generate_report.py'. Let's test it with the example records from earlier in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a533c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamodb = boto3.resource(\"dynamodb\")\n",
    "\n",
    "table_name = \"deep-research-evidence\"\n",
    "table = dynamodb.Table(table_name)\n",
    "\n",
    "records = [record for record in table.scan().get(\"Items\")[:2]]\n",
    "question = records[0][\"question\"]\n",
    "evidence = [record.get(\"evidence_id\") for record in records]\n",
    "\n",
    "print(question)\n",
    "print(evidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f712863b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from strands import Agent\n",
    "from generate_report import generate_report_tool\n",
    "import os\n",
    "\n",
    "os.environ[\"EVIDENCE_TABLE_NAME\"] = table_name\n",
    "\n",
    "MODEL_ID = \"global.anthropic.claude-sonnet-4-20250514-v1:0\"\n",
    "agent = Agent(tools=[generate_report_tool], model=MODEL_ID)\n",
    "\n",
    "# Send a message to the agent\n",
    "result = agent.tool.generate_report_tool(\n",
    "    prompt=f\"Please write a concise report that answers the question, {question}\",\n",
    "    evidence_ids=evidence,\n",
    ")\n",
    "\n",
    "print(result.get(\"content\")[0][\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72739847",
   "metadata": {},
   "source": [
    "This \"agent\" can be used by our lead agent to generate cited, well-written final reports."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b4881e",
   "metadata": {},
   "source": [
    "## 4. Create Lead Agent\n",
    "\n",
    "Now that we've defined all of our subagents and tools, we're ready to create our lead agent. This agent will be responsible for planning, updating files, and assigning tasks but NOT to any of the research activities. This separation of concerns allows us to opimize the token usage and simplify the agent definitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6d3f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pmc_research_agent import pmc_research_agent\n",
    "from strands import Agent, tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def research_agent(prompt: str) -> str:\n",
    "    \"\"\"\n",
    "    AI agent for researching scientific questions using articles from PubMed Central (PMC).\n",
    "\n",
    "    You may delegate research tasks to this agent by providing clear text instructions in the prompt.\n",
    "\n",
    "    Args:\n",
    "        prompt: Scientific question to research using articles from PMC\n",
    "\n",
    "    Returns:\n",
    "        Concise answer to the question based on the most relevant evidence, followed by a list of the associated `evidence_id` values for citation analysis.\n",
    "    \"\"\"\n",
    "    return pmc_research_agent(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dba2184",
   "metadata": {},
   "outputs": [],
   "source": [
    "from strands import Agent\n",
    "from strands.models import BedrockModel\n",
    "from strands_tools import editor\n",
    "from pmc_research_agent import pmc_research_agent\n",
    "from generate_report import generate_report_tool\n",
    "from lead_config import SYSTEM_PROMPT, MODEL_ID\n",
    "\n",
    "import os\n",
    "\n",
    "model = BedrockModel(\n",
    "    model_id=MODEL_ID,\n",
    "    max_tokens=10000,\n",
    "    cache_prompt=\"default\",\n",
    "    temperature=1,\n",
    "    additional_request_fields={\n",
    "        \"anthropic_beta\": [\"interleaved-thinking-2025-05-14\"],\n",
    "        \"reasoning_config\": {\n",
    "            \"type\": \"enabled\",\n",
    "            \"budget_tokens\": 3000,\n",
    "        },\n",
    "    },\n",
    ")\n",
    "\n",
    "os.environ[\"BYPASS_TOOL_CONSENT\"] = \"true\"\n",
    "\n",
    "lead_agent = Agent(\n",
    "    model=model,\n",
    "    system_prompt=SYSTEM_PROMPT,\n",
    "    tools=[research_agent, generate_report_tool, editor],\n",
    ")\n",
    "\n",
    "response = lead_agent(\n",
    "    \"How safe and effective are GLP-1 drugs for long term use? Please limit your output report to only 3 sections\"\n",
    ")\n",
    "response = lead_agent(\"I approve the outline. Please proceed.\")\n",
    "\n",
    "response.metrics.accumulated_usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08dfa7f",
   "metadata": {},
   "source": [
    "## 5. Deploy to Amazon Bedrock AgentCore Runtime\n",
    "\n",
    "Let's look at the new agent definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f802918f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pycat lead_agent.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6cfe0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bedrock_agentcore_starter_toolkit import Runtime\n",
    "\n",
    "agentcore_runtime = Runtime()\n",
    "agentcore_runtime.configure(\n",
    "    agent_name=\"lead_agent\",\n",
    "    auto_create_ecr=True,\n",
    "    auto_create_execution_role=True,\n",
    "    entrypoint=\"lead_agent.py\",\n",
    "    memory_mode=\"NO_MEMORY\",\n",
    "    requirements_file=\"requirements.txt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d438cac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "agentcore_runtime.launch(auto_update_on_conflict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b1463d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "agentcore_runtime.invoke(\n",
    "    {\"prompt\": \"How safe and effective are GLP-1 drugs for long term use?\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6a0a4b",
   "metadata": {},
   "source": [
    "## 6. (Optional) Interact with agent using AgentCore Chat\n",
    "\n",
    "Follow these steps to open an interactive chat session with your new agent.\n",
    "\n",
    "1. Open a command line terminal in your notebook environment.\n",
    "2. Navigate to the project root folder (where `pyproject.toml` is located).\n",
    "3. Run `pip install .` to install the workshop tools including the chat CLI.\n",
    "4. Run `agentcore-chat` to launch the CLI.\n",
    "5. Select the `lead_agent` by typing its name or index in the terminal and press Enter.\n",
    "6. Ask your question at the `You:` prompt and press Enter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e0562a",
   "metadata": {},
   "source": [
    "## 7. (Optional) Clean Up\n",
    "\n",
    "Run the next notebook cell to delete the AgentCore runtime environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bad2ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "agentcore_client = boto3.client(\"bedrock-agentcore-control\")\n",
    "agent_status = agentcore_runtime.status()\n",
    "\n",
    "agentcore_client.delete_agent_runtime(agentRuntimeId=agent_status.config.agent_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
